### Goku Mohandas

#### Recommendation Engines

- [Deep Neural Networks for Youtube Recommendations] (notes/youtube_recommendations.md) [[Google] (https://research.google.com/pubs/pub45530.html)]


#### Representation Learning

- [Doctor AI: Predicting Clinical Events via Recurrent Neural Networks] (notes/docai.md) [[arXiv] (http://arxiv.org/abs/1511.05942)]

- [Distributed Representations of Words and Phrases and their Compositionality] (notes/word2vec_mikolov.md) [[NIPS] (https://papers.nips.cc/paper/5021-distributed-representations-of-words-and-phrases-and-their-compositionality.pdf)]

- Multi-layer Representation Learning for Medical Concepts [[arXiv] (https://arxiv.org/abs/1602.05568)]


#### Text Classification

 - [Convolutional Neural Networks for Sentence Classification] (notes/cnn_text.md) [[arXiv] (http://arxiv.org/abs/1408.5882)]
  
 - Recurrent Neural Network Regularization [[arXiv] (http://arxiv.org/abs/1409.2329)]
 
 - Grammar as a Foreign Language [[arXiv] (http://arxiv.org/abs/1412.7449)]
 
 
#### Seq-to-Seq Models (translation)
 
 - [Sequence to Sequence Learning with Neural Networks] (notes/seq_to_seq_rnn.md) [[arXiv] (https://arxiv.org/abs/1409.3215)]
 
 - [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation] (notes/rnn_encode_decode.md) [[arXiv] (http://arxiv.org/abs/1406.1078)]
 
- [Neural Machine Translation by Jointly Learning to Align and Translate] (notes/rnn_attention.md) [[arXiv] (http://arxiv.org/abs/1409.0473)] - Attention in RNNs
 
- [On Using Very Large Target Vocabulary for Neural Machine Translation] (notes/rnn_softmax.md) [[arXiv] (http://arxiv.org/abs/1412.2007)] - Sampled Softmax 

- [Pointer Sentinel Mixture Models] (notes/pointer_sentinel.md) [[arXiv](https://arxiv.org/abs/1609.07843)]

- [Context-Dependent Word Representation for Neural Machine Translation] (notes/context.md) [[arXiv](https://arxiv.org/abs/1607.00578)]

- [Learning to Translate in Real-time with Neural Machine Translation] (notes/real_time_NMT.md) [[arXiv](https://arxiv.org/abs/1610.00388)]

- [Fully Character-Level Neural Machine Translation without Explicit Segmentation] (notes/fully_char.md) [[arXiv](https://arxiv.org/abs/1610.03017)]


#### Neural Conversation Models / QA

 - [A Neural Conversational Model] (notes/conversation.md) [[arXiv] (http://arxiv.org/abs/1506.05869)]
 
 - End-To-End Memory Networks [[arXiv](https://arxiv.org/abs/1503.08895)]
 
- [Ask Me Anything: Dynamic Memory Networks for Natural Language Processing] (notes/ama.md) [[arXiv](https://arxiv.org/abs/1506.07285)]
 
- [Dynamic Memory Networks for Visual and Textual Question Answering] (notes/visual_qa.md) [[arXiv](https://arxiv.org/abs/1603.01417)] 
 
- [Dynamic Coattention Networks For Question Answering] (notes/coattention.md) [[arXiv](https://arxiv.org/abs/1611.01604)]

- [Richard Socher on the Future of Deep Learning] (notes/future_socher.md) [[OReilly](https://www.oreilly.com/ideas/richard-socher-on-the-future-of-deep-learning)]

- [A Joint Many-Task Model: Growing a Neural Network for Multiple NLP Tasks][[arXiv](https://arxiv.org/abs/1611.01587)]

- [Bidirectional Attention Flow for Machine Comprehension][[arXiv](https://arxiv.org/abs/1611.01603)]


#### Logic/Reasoning

- [Chains of Reasoning over Entities, Relations, and Text using Recurrent Neural Networks] [[arXiv](https://arxiv.org/abs/1607.01426)]

- [Deep API Learning] [[arXiv](https://arxiv.org/abs/1605.08535)]


#### Reinforcement Learning

- Episodic Exploration for Deep Deterministic Policies: An Application to StarCraft Micromanagement Tasks [[arXiv] (http://arxiv.org/abs/1609.02993)]

- Third Person Imitation Learning [[arXiv](http://openreview.net/pdf?id=B16dGcqlx)]


#### Google DeepMind

- WaveNet: A Generative Model for Raw Audio [[arXiv] (https://arxiv.org/abs/1609.03499)][[Tutorial] (https://deepmind.com/blog/wavenet-generative-model-raw-audio/)]

- Decoupled Neural Interfaces using Synthetic Gradients [[arXiv] (https://arxiv.org/abs/1608.05343)] [[Tutorial] (https://deepmind.com/blog/decoupled-neural-networks-using-synthetic-gradients/)]


#### Neural Turing Machines

- [Neural Turing Machines] (notes/ntm.md) [[arXiv] (http://arxiv.org/abs/1410.5401)]

- [Hybrid Computing using a Neural Network with Dynamic External Memory] [[Nature](https://goo.gl/8T4EST)]


#### Generative Adversarial Networks

- [Generative Adversarial Networks] (notes/GAN.md) [[arXiv] (https://arxiv.org/abs/1406.2661)]

-  [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](notes/dcgan.md) [[arXiv](http://arxiv.org/abs/1511.06434v2)]

- [Generative Adversarial Text to Image Synthesis](notes/text2image.md) [[arXiv] (https://arxiv.org/abs/1605.05396)]

- [Improved Techniques for Training GANs](notes/improved_gan.md) [[arXiv] (https://arxiv.org/abs/1606.03498)]

- [Learning to Protect Communications with Adversarial Neural Cryptography](notes/crypto_gan.md) [[arXiv](https://arxiv.org/abs/1610.06918)]


#### Image Captioning

- [Show, Attend and Tell: Neural Image Caption Generation with Visual Attention](notes/show_attend_tell.md) [[arXiv](https://arxiv.org/abs/1502.03044)]


#### Review Papers

- [Understanding deep learning requires rethinking generalization] [[arXiv] (https://arxiv.org/abs/1505.00387)]


#### Optimization/Architecture

- [Highway Networks] (notes/highway.md) [[arXiv] (https://arxiv.org/abs/1611.03530)]

- [Maxout Networks] [[arXiv](https://arxiv.org/abs/1302.4389)]

- [HyperNetworks] (notes/hypernetworks.md) [[arXiv] (https://arxiv.org/abs/1609.09106)]

- [Using Fast Weights to Attend to the Recent Past] (notes/fast_weights.md) [[arXiv] (https://arxiv.org/abs/1610.06258)]

- [Quasi-Recurrent Neural Networks](notes/quasi.md) [[arXiv](https://arxiv.org/abs/1611.01576)]

- [Learning to learn by gradient descent by gradient descent] [[arXiv](https://arxiv.org/abs/1606.04474)]

- [Language Modeling with Gated Convolutional Networks] [[arXiv](https://arxiv.org/abs/1612.08083)]

- [Value Iteration Networks] [[arXiv](https://arxiv.org/abs/1602.02867)]

- [Adding Gradient Noise Improves Learning for Very Deep Networks] [[arXiv](https://arxiv.org/abs/1511.06807)]

- [Outrageously Large Neural Networks: The Sparsely-gated Mixture-of-Experts Layer] [[Open Review](https://openreview.net/pdf?id=B1ckMDqlg)]

